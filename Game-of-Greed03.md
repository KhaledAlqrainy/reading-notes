# Dunder methods

> methods that start and end with double underscores, for example __init__ or __str__, it let you emulate the behavior of built-in types, and  let you emulate the behavior of built-in types.


### Object Initialization: __init__

* it construct account objects from the Account class, The constructor takes care of setting up the object.

### Object Representation: __str__, __repr__

* It’s common practice in Python to provide a string representation of your object for the consumer of your class (a bit like API documentation.) 

**__repr__:** The “official” string representation of an object. This is how you would make an object of the class. The goal of __repr__ is to be unambiguous.

**__str__:** The “informal” or nicely printable string representation of an object. This is for the enduser.

### Operator Overloading for Merging Accounts: __add__

* **__add__** is to merge two accounts. The expected behavior would be to merge all attributes together

### Callable Python Objects: __call__

* by adding the __call__ dunder method we You can make an object callable like a regular function.

it can be hard to see what the purpose of calling the object is

### Context Manager Support and the With Statement: __enter__, __exit__

> A context manager is a simple “protocol” (or interface) that your object needs to follow so it can be used with the with statement. Basically all you need to do is add __enter__ and __exit__ methods to an object if you want it to function as a context manager.



#  Statistics in Python - Probability

* Probability seeks to answer the question, “What is the chance of an event happening?” An event is some outcome of interest. To calculate the chance of an event happening, we also need to consider all the other events that can occur. The quintessential representation of probability is the humble coin toss.

*  We can use statistics to calculate probabilities based on observations from the real world and check how it compares to the ideal.

### From statistics to probability

* Data will be generated by flipping a coin 10 times and counting how many times we get heads. We will call a set of 10 coin tosses a trial. Our data point will be the number of heads we observe. We may not get the “ideal” 5 heads, but we won’t worry too much since one trial is only one data point. If we perform many, many trials, we expect the average number of heads over all of our trials to approach the 50%. 

### The data and the distribution

*  The normal distribution refers to a particularly important phenomenon in the realm of probability and statistics

* The most important qualities to notice about the normal distribution is its symmetry and its shape. We’ve been calling it a distribution, but what exactly is being distributed? It depends on the context. In probability, the normal distribution is a particular distribution of the probability across all of the events

* In a probability context, the high point in a normal distribution represents the event with the highest probability of occurring. As you get farther away from this event on either side, the probability drops rapidly, forming that familiar bell-shape. 



**The normal distribution is significant to probability and statistics thanks to two factors: the Central Limit Theorem and the Three Sigma Rule.**

### Central Limit Theorem

* The Central Limit Theorem dictates that the distribution of these estimates will look like a normal distribution. The zenith of this distribution will line up with the true value that the estimates should take on.

* The Central Limit Theorem suggests that we can hone in on the theoretical ideal given by probability, even when we don’t know the true probability. Central Limit Theorem lets us know that the average of many trials means will approach the true mean.


### Three Sigma Rule

* An expression of how many of our observations fall within a certain distance of the mean. Remember that the standard deviation (a.k.a. “sigma”) is the average distance an observation in the data set is from the mean.

* The Three Sigma rule dictates that given a normal distribution, 68% of your observations will fall between one standard deviation of the mean. 95% will fall within two, and 99.7% will fall within three.

### Z-score

*  Z-score doesn’t provide much information to you. It gains the most value when compared against a Z-table, which tabulates the cumulative probability of a standard normal distribution up until a given Z-score. 

*  The mean is the exact middle of the normal distribution, so we know that the sum of all probabilites of getting values from the left side up until the mean is 50%. The values from the Three Sigma Rule actually come up if you try to calculate the cumulative probability between standard deviations. 